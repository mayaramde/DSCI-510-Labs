{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dJcGMea_6m0"
   },
   "source": [
    "Lab 9 (Week-10)\n",
    "-----------------------------------------\n",
    "Hey Everyone, \n",
    "\n",
    "Guidelines for the Lab:\n",
    "- Download the lab materials from D2L. You're supposed to complete it by the deadline, Sunday (27th March) 4pm PDT.  \n",
    "\n",
    "- You have to complete the assignments individually. If you are having trouble completing the assignment do let the TA's/CP's or Graders know.\n",
    "\n",
    "- Please don't copy code (either partially/fully) from your classmates. Plagiarism of any form will result in a 0 and you will be reported to SJACS (https://sjacs.usc.edu/students/academic-integrity/).\n",
    "\n",
    "- You have to fill the code in this notebook and upload it for submission. While doing this, make sure all supporting files that you download from D2L are in the same directory as this notebook.  \n",
    "\n",
    "- Please don't submit code in text files and .py files. Also no mailing code to the TA's or Graders. There were exemptions provided to students in earlier labs due to D2L issues, environment setup and course registrations but these exemptions will not be carried over to future labs.\n",
    "\n",
    "- File Naming Convention : Lab9_FIRSTNAME_LASTNAME.ipynb (Failure to comply to this policy may incur penalties ).\n",
    "\n",
    "- Don't change existing methods (if any, unless otherwise mentioned in the instructions)\n",
    "\n",
    "- You are encouraged to look up resources online like python docs and stackoverflow. But, you are encouraged to look up the topics and not the questions themselves.  \n",
    "\n",
    "- Your last submission before the deadline will be counted towards your grade. You can submit any number of times before the deadline.\n",
    "\n",
    "- Scores are capped at 10 points including the Bonus problem. For Example : Even if you get a score of 12/10, your score is capped at 10.\n",
    "\n",
    "- Your output should be as mentioned in the question (Don't output/print extra items which are not asked in the question as it makes it difficult for the graders to grade). (Failure to comply to this policy may incur penalties)\n",
    "\n",
    "- You need to take input from file/console only if it is mentioned in the question. If not we need just the logic/implementation of your function.\n",
    "\n",
    "- Please Don't ask for changes to the Grading Rubrics. Some questions have all/nothing rubric and missing one test case/ edge case may result in a 0 score. So you are encouraged to write your own test cases and evaluate your code as and where necessary. The TA's or Graders will not be providing you with the test cases.\n",
    "\n",
    "----------------------------------------------\n",
    "- To make coding easier, a lot of the boilerplate code has been given as a template to show you first hand how OOPs constructs are designed. Please use them as references.\n",
    "\n",
    "- Don't change the existing boilerplate code. The reason the boilerplate code has been given, is to make it easy for you to see the bigger picture and get you up to speed faster. There have been multiple comments added, to make it easier for students to logically comprehend the sequence of steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's lab is about BeautifulSoup and requests.  \n",
    "\n",
    "Some hints before you go: \n",
    "- Use the ```type``` function and ```dir``` function whenever possible to understand what you have vs what did you expect.\n",
    "- Give attention to the brackets while looking at a json so, that you know what you will get after parsing it. \n",
    "- Similarly, give attention to the tags while looking at html code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyLxMqux_6m3"
   },
   "source": [
    "Q1. (5 points)\n",
    "---\n",
    "\n",
    "For this question, we will scrape the website \"https://www.nytimes.com/\".  \n",
    "\n",
    "For all news headlines for the website, you have to look for the link to the article and the headline text which **contains the keyword(specifically, in the headline) passed to you in the function argument**.  \n",
    "\n",
    "For the return values, you have to return a list of tuples where a particular tuple's 0th value is the link to the article and the 1st value is the headline text.   \n",
    "\n",
    "Note: Call ```strip()``` over the link and the headline text, so that it is more readable.  \n",
    "\n",
    "FAQs:  \n",
    "Q. How to read/parse a website?  \n",
    "A. For that, as taught in the class you would need to use libraries like BeautifulSoup, urllib or requests.  \n",
    "\n",
    "Q. What am I getting anyway when I read the website?  \n",
    "A. You are getting the whole html code written for the website, when you read/parse the website.  \n",
    "\n",
    "Q. I don't know html, what should I do?  \n",
    "A. For this lab, you only need to understand that html is another type of a language made up of tags. For example, it has heading info in the head tag, paragraph has p tag, and html links have a tag. So, using the tag, you can get the info you need! A more comprehensive tutorial is found here for beginners : https://www.w3schools.com/html/\n",
    "\n",
    "Q. How do I get the tag info?  \n",
    "A. When you get your BeautifulSoup object you can do something like object.find_all('tag') or object('tag') to get all 'tag' tags.  \n",
    "\n",
    "Q. I got the tag, but what I got seems cryptic. What now?  \n",
    "A. So, once you get the info from a particular tag, you get the whole html code inside that tag. If you want some particular information from that, you would need to call functions like get and get_text to get the information directly without messing with the html code.  \n",
    "\n",
    "Q. I am not sure how to use these functions. documentation?  \n",
    "A. You can read from the official documentation. Link: https://www.crummy.com/software/BeautifulSoup/bs4/doc/  \n",
    "\n",
    "Good Feature: Use the .prettify() feature of BeautifulSoup. You'll get a better insight of what is that you are scrapping. \n",
    "\n",
    "---\n",
    "\n",
    "Grading Rubric: All or Nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "o888ilyK_6m3"
   },
   "outputs": [],
   "source": [
    "# Uncomment following line to install beautifulsoup if you find out that you don't have it\n",
    "#!pip install bs4\n",
    "#!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_news_of(keyword):\n",
    "    content = requests.get('https://www.nytimes.com/')\n",
    "    soup = BeautifulSoup(content.content, 'html.parser')\n",
    "    \n",
    "    return_list = []\n",
    "    \n",
    "    all_a = soup.find_all('a') # finds all html links to article titles\n",
    "    \n",
    "    for tag_a in all_a:\n",
    "        if keyword.lower() in tag_a.get_text().strip().lower():\n",
    "            return_list.append((tag_a.get('href').strip(), tag_a.get_text().strip()))\n",
    "\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "tsKVtxqc_6m4",
    "outputId": "fb30fb2c-4ab2-46fc-e301-165617263555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.nytimes.com/live/2022/03/28/world/ukraine-russia-war',\n",
       "  'Russia-Ukraine War14m ago'),\n",
       " ('https://www.nytimes.com/live/2022/03/28/world/ukraine-russia-war',\n",
       "  'LIVEMarch 28, 2022, 6:51 p.m. ETSays U.S. Is Not Seeking to Remove Russian LeaderPresident Biden stood by his comment that Vladimir Putin should be removed as Russia’s president, saying he was “expressing the moral outrage I felt.”Despite talk of Russia targeting the east of Ukraine, action on several battlefronts suggested a more dynamic and volatile situation. Here’s the latest.See 9+ more updates ›'),\n",
       " ('https://www.nytimes.com/2022/03/28/world/europe/irpin-donbas-poison.html',\n",
       "  'Ukraine Claims Some Battle Successes as Russia Focuses on Another FrontWith the fighting raging, diplomacy between the two sides was continuing, with talks planned in Istanbul on Tuesday.'),\n",
       " ('https://www.nytimes.com/2022/03/28/world/europe/macron-france-russia-ukraine.html',\n",
       "  'The president of France reaches out often to Russia and Ukraine, but whether his diplomacy is effective remains to be seen.'),\n",
       " ('https://www.nytimes.com/live/2022/03/28/world/ukraine-russia-war/a-video-shows-russian-prisoners-of-war-in-ukraine-being-beaten-and-shot-in-their-legs',\n",
       "  'A video shows Russian prisoners of war in Ukraine being beaten and shot.'),\n",
       " ('https://www.nytimes.com/video/world/europe/100000008206442/russia-military-ukraine.html',\n",
       "  'Tracking Russia’s Latest Military Movements Around Ukraine'),\n",
       " ('https://www.nytimes.com/video/world/europe/100000008206442/russia-military-ukraine.html',\n",
       "  'Tracking Russia’s Latest Military Movements Around Ukraine'),\n",
       " ('https://www.nytimes.com/2022/03/28/world/middleeast/arab-israeli-summit.html',\n",
       "  'Israeli Summit Mixes Historic Symbolism With Sharp DisputesThe meeting of diplomats was momentous just for taking place. But in private, they tried to hash out differences over Iran and the war in Ukraine.')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_of('Ukraine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbGFXo-s_6m4"
   },
   "source": [
    "Q2. (5 points)\n",
    "---\n",
    "\n",
    "For this question, we will be using beautiful soup to Scrap Table of Contents from a Wiki page.\n",
    "Given a wikipedia article, https://en.wikipedia.org/wiki/Transhumanism we want to list all the table of contents\n",
    "in a separate line.\n",
    "\n",
    "For example output of the table of contents of the above page would be \n",
    "\n",
    "```\n",
    "1 History\n",
    "1.1 Precursors of transhumanism\n",
    "1.2 Early transhumanist thinking\n",
    "1.3 Artificial intelligence and the technological singularity\n",
    "1.4 Growth of transhumanism\n",
    "2 Theory\n",
    "2.1 Aims\n",
    "2.2 Empathic fallibility and conversational consent\n",
    "2.3 Ethics\n",
    "....\n",
    "....etc\n",
    "\n",
    "```\n",
    "\n",
    "The step wise pseudo code is written below in the comments for reference.\n",
    "\n",
    "---\n",
    "\n",
    "Grading Rubric: -0.5 for each wrong line in the output for the above wiki page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "4i3dpA_r_6m5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 History\n",
      "1.1 Precursors of transhumanism\n",
      "1.2 Early transhumanist thinking\n",
      "1.3 Artificial intelligence and the technological singularity\n",
      "1.4 Growth of transhumanism\n",
      "2 Theory\n",
      "2.1 Aims\n",
      "2.2 Empathic fallibility and conversational consent\n",
      "2.3 Ethics\n",
      "2.4 Currents\n",
      "2.5 Spirituality\n",
      "3 Practice\n",
      "3.1 Technologies of interest\n",
      "4 Debate\n",
      "4.1 Feasibility\n",
      "4.2 Intrinsic immorality\n",
      "4.3 Loss of human identity\n",
      "4.4 Socioeconomic effects\n",
      "4.4.1 Cultural aesthetics\n",
      "4.5 Specter of coercive eugenicism\n",
      "4.6 Existential risks\n",
      "5 See also\n",
      "6 References\n",
      "7 Further reading\n",
      "8 External links\n"
     ]
    }
   ],
   "source": [
    "#Import as necessary\n",
    "#!pip install lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Transhumanism'\n",
    "# get contents from url using requests.get\n",
    "content = requests.get(url)\n",
    "\n",
    "# get soup like BeautifulSoup(content,'lxml') , choose lxml parser\n",
    "soup = BeautifulSoup(content.content, 'lxml')\n",
    "\n",
    "# find the tag : <div class=\"toc\">\n",
    "# id=\"toc\" also works\n",
    "tags = soup.find('div', {'class' : 'toc'})\n",
    "\n",
    "# get all the links like for example tag.findAll('a') for <a href='/path/to/div'>topic</a>\n",
    "all_a = tags.findAll('a')\n",
    "\n",
    "# print them\n",
    "for tag_a in all_a:\n",
    "    print(tag_a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZONybQGS_6m6"
   },
   "source": [
    "Q3 - Bonus MCQ question (2 points).\n",
    "---\n",
    "\n",
    "What does the following block of code do?\n",
    "\n",
    "```\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "site = \"https://www.google.com\"\n",
    "html = urllib.request.urlopen(site).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "```\n",
    "A. retrieves and displays the webpage\n",
    "\n",
    "B. parses the html content of \"https://www.google.com\"\n",
    "\n",
    "C. downloads the webpage\n",
    "\n",
    "D. None of the above\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-fk1YYv_6m6"
   },
   "source": [
    "Ans: B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab7Rubric.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
